---
title: "Assignment _Chapter_06"

author: "XIAOYAN YUE"

---
##6E1 State the three motivating criteria that define information entropy. Try to express each in your own words.
(1)The variation of information entropy are continuous.

(2)The information entropy vary with the number of possible events.The more number of possible events, the larger of the information entropy should be.

(3)The information entropy of different possible events could be additive.

##6E2 Suppose a coin is weighted such that, when it is tossed and lands on a table, it comes up heads 70% of the time. What is the entropy of this coin?
calculate formula:

H(p) = - (0.3*log0.3)+(0.7*log0.7))

R calculation:
```{r}
p <- c( 0.3 , 0.7 )
-sum( p*log(p) )
```

##6E3 Suppose a four-sided die is loaded such that, when tossed onto a table, it shows ¡°1¡± 20%, ¡°2¡± 25%, ¡±3¡± 25%, and ¡±4¡± 30% of the time. What is the entropy of this die?
```{r}
p <- c(0.20,0.25,0.25,0.30 )
-sum( p*log(p) )
```
##6E4 Suppose another four-sided die is loaded such that it never shows ¡°4¡±. The other three sides show equally often. What is the entropy of this die?
```{r}
p <- c(0.33,0.33,0.33,0 )
-sum( p*log(p) )
```
